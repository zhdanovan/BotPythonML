{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "discrete-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reserved-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BIG_BOT_CONFIG.json','r') as f:\n",
    "    BOT_CONFIG=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marine-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text): \n",
    "    cleaned_text = ''\n",
    "    for ch in text.lower():\n",
    "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz ':\n",
    "            cleaned_text = cleaned_text + ch\n",
    "    return cleaned_text\n",
    "\n",
    "def match(text, example): \n",
    "    return nltk.edit_distance(text, example) / len(example) < 0.4 if len(example) > 0 else False\n",
    "\n",
    "def get_intent(text): \n",
    "    for intent in BOT_CONFIG['intents']:\n",
    "        if 'examples' in BOT_CONFIG['intents'][intent]:\n",
    "             for example in BOT_CONFIG['intents'][intent]['examples']:\n",
    "                if match(cleaner(text), cleaner(example)):\n",
    "                       return intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggressive-multimedia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for intent in BOT_CONFIG['intents']:\n",
    "     if 'examples' in BOT_CONFIG['intents'][intent]:\n",
    "        X += BOT_CONFIG['intents'][intent]['examples']\n",
    "        y += [intent for i in range(len(BOT_CONFIG['intents'][intent]['examples']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "photographic-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(preprocessor=cleaner, ngram_range=(1,3), stop_words=['а', 'и'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranking-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(X)\n",
    "X_vect = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spatial-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect, X_test_vect, y_train, y_test = train_test_split(X_vect, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "portuguese-dayton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier() \n",
    "sgd.fit(X_vect, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "described-architecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829935622317596"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.score(X_vect, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "active-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent_by_model(text): # Функция определяющая интент текста с помощью ML-модели\n",
    "     return sgd.predict(vectorizer.transform([text]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "twenty-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot(text): # функция бота\n",
    "    intent = get_intent(text)  # 1. попытаться понять намерение сравнением по Левинштейну\n",
    "    \n",
    "    if intent is None:\n",
    "        intent = get_intent_by_model(text) # 2. попытаться понять намерение с помощью ML-модели\n",
    "\n",
    "    return random.choice(BOT_CONFIG['intents'][intent]['responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-lebanon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет\n",
      "И вам хорошего дня\n",
      "Как дела?\n",
      "Шалом, юзер\n",
      "Что делаешь?\n",
      "До новых встреч!\n",
      "Что?\n",
      "Привет, всё хорошо?\n",
      "Погоди, о чем ты?\n",
      "Благодарю. Я обязательно передам это своим разработчикам!\n",
      "Ок\n",
      "и..? =)\n",
      "Как жизнь?\n",
      "I’m OK.\n"
     ]
    }
   ],
   "source": [
    "question = ''\n",
    "while question not in ['выход', 'выключайся']:\n",
    "    question = input()\n",
    "    answer = bot(question)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-telling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-generator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
